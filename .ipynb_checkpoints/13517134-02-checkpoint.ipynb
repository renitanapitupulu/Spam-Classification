{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Babe, I'm back ... Come back to me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>S:)no competition for him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yup having my lunch buffet now.. U eat already?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Storming msg: Wen u lift d phne, u say HELLO D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Mark works tomorrow. He gets out at 5. His wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type                                               text\n",
       "0  ham             Babe, I'm back ... Come back to me ...\n",
       "1  ham                         S:)no competition for him.\n",
       "2  ham    Yup having my lunch buffet now.. U eat already?\n",
       "3  ham  Storming msg: Wen u lift d phne, u say HELLO D...\n",
       "4  ham  Mark works tomorrow. He gets out at 5. His wor..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "#df_train, df_val, df_test\n",
    "df_train = pd.read_csv('spam.zip/training_data.csv')\n",
    "df_val = pd.read_csv('spam.zip/val_data.csv')\n",
    "df_test = pd.read_csv('spam.zip/testing_data.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#Preproses data yang digunakan yaitu terdiri dari 4 tahap yaitu tokenization, remove punctuation, lemmatization, dan stopword elimination\n",
    "def preprocessing(text):\n",
    "    # 1. Tokenization using nltk\n",
    "    tokens =  nltk.word_tokenize(text)\n",
    "    # 2. Remove punctuation\n",
    "    remove_punc = [token for token in tokens if token.isalpha()]\n",
    "    # 3. Normalization (lemmatization) using nltk\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    after_lemma = [lemmatizer.lemmatize(w) for w in remove_punc]\n",
    "    # 4. Stopword elimination using nltk\n",
    "    elim_stop_word = ' '.join([word for word in after_lemma if not word.lower() in stopwords.words('english')])\n",
    "    \n",
    "    return elim_stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data = df_train.text.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     Babe back Come back\n",
      "1                                             competition\n",
      "2                          Yup lunch buffet U eat already\n",
      "3       Storming msg Wen u lift phne u say HELLO u knw...\n",
      "4       Mark work tomorrow get work house meet u after...\n",
      "                              ...                        \n",
      "4497                   Hi sorry missed call pls call back\n",
      "4498    Hello Sort town already dont rush home eating ...\n",
      "4499                           Free Msg Ringtone http wml\n",
      "4500                   Yes tv always available work place\n",
      "4501    dude fake frnds got money thts reffering u u m...\n",
      "Name: text, Length: 4502, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# feature extraction menggunakan tf-idf yang sudah didefinisikan sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# fit transform akan melakukan transformasi terhadap hasil data yang sudah dipreproses sebelumnya\n",
    "X = vectorizer.fit_transform(preprocess_data)\n",
    "\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with n_neighbors = 1  : 0.9540918163672655\n",
      "Accuracy with n_neighbors = 3  : 0.9301397205588823\n",
      "Accuracy with n_neighbors = 5  : 0.9101796407185628\n",
      "Accuracy with n_neighbors = 7  : 0.9001996007984032\n"
     ]
    }
   ],
   "source": [
    "# 1.Using KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# parameter yang dipilih yaitu berdasarkan jumlah neighbor yang digunakan pada model\n",
    "neighbor = [1,3,5,7]\n",
    "knn_model = []\n",
    "for n in neighbor:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    # train model using training set\n",
    "    knn.fit(X, df_train.type)\n",
    "    \n",
    "    # predict val data\n",
    "    val_type_predict =  knn.predict(vectorizer.transform(df_val.text))\n",
    "    # calculate model accuracy using metrics.accuracy_score\n",
    "    print(\"Accuracy with n_neighbors =\" , n, \" :\",metrics.accuracy_score(df_val.type, val_type_predict))\n",
    "    knn_model.append(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with n_neighbors = 1 : 0.947841726618705\n"
     ]
    }
   ],
   "source": [
    "# Clasification use model with n_neighbors = 1\n",
    "test_type_predict =  knn_model[0].predict(vectorizer.transform(df_test.text))\n",
    "print(\"Accuracy with n_neighbors = 1 :\",metrics.accuracy_score(df_test.type, test_type_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham'\n",
      " 'ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "print(test_type_predict[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM with kernel ' linear ' : 0.9820359281437125\n",
      "Accuracy SVM with kernel ' poly ' : 0.9421157684630739\n",
      "Accuracy SVM with kernel ' rbf ' : 0.9820359281437125\n",
      "Accuracy SVM with kernel ' sigmoid ' : 0.9780439121756487\n"
     ]
    }
   ],
   "source": [
    "# 2. Using SVM yang telah disediakan sklearn\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# parameter yang dipilih yaitu berdasarkan tipe kernel yang digunakan pada model\n",
    "kernel_type = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "svm_model = []\n",
    "for k in kernel_type:\n",
    "    clf = SVC(kernel=k)\n",
    "    \n",
    "    #train model\n",
    "    clf.fit(X, df_train.type)\n",
    "    \n",
    "    # predict val data\n",
    "    val_type_predict =  clf.predict(vectorizer.transform(df_val.text))\n",
    "    # calculate model accuracy using metrics.accuracy_score\n",
    "    print(\"Accuracy SVM with kernel '\", k, \"' :\",metrics.accuracy_score(df_val.type, val_type_predict))\n",
    "    svm_model.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM with kernel 'linear' :  0.9820143884892086\n"
     ]
    }
   ],
   "source": [
    "# Choose clasification model SVM with kernel = linear\n",
    "test_type_predict =  svm_model[0].predict(vectorizer.transform(df_test.text))\n",
    "print(\"Accuracy SVM with kernel 'linear' : \",metrics.accuracy_score(df_test.type, test_type_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham'\n",
      " 'ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "print(test_type_predict[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest with criterion ' gini ' : 0.9820359281437125\n",
      "Accuracy Random Forest with criterion ' entropy ' : 0.9780439121756487\n"
     ]
    }
   ],
   "source": [
    "# 3. Using RandomForest yang telah disediakan sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# parameter yang dipilih yaitu berdasarkan tipe criterion yang digunakan pada model\n",
    "criterion_type = ['gini', 'entropy']\n",
    "rf_model = []\n",
    "for c in criterion_type:\n",
    "    spam_model_rf = RandomForestClassifier(criterion=c, random_state=0, n_estimators=50)\n",
    "\n",
    "    #train model\n",
    "    spam_model_rf.fit(X,df_train.type)\n",
    "    \n",
    "    # predict val data\n",
    "    val_type_predict =  spam_model_rf.predict(vectorizer.transform(df_val.text))\n",
    "    # calculate model accuracy using metrics.accuracy_score\n",
    "    print(\"Accuracy Random Forest with criterion '\", c, \"' :\",metrics.accuracy_score(df_val.type, val_type_predict))\n",
    "    rf_model.append(spam_model_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest with criterion 'gini' :  0.9820143884892086\n"
     ]
    }
   ],
   "source": [
    "# Choose clasification model RF with criterion = gini\n",
    "test_type_predict =  rf_model[0].predict(vectorizer.transform(df_test.text))\n",
    "print(\"Accuracy Random Forest with criterion 'gini' : \",metrics.accuracy_score(df_test.type, test_type_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham'\n",
      " 'ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "print(test_type_predict[:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
